{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Straight Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prompts\n",
    "import json \n",
    "import random\n",
    "from codesim.prompt import StraightLine as SL\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/StraightLine/n_ops-20_n_vars-3_n_instances-2_batch-1.json\"))\n",
    "p_syn, p_nat, lab_syn, lab_nat = data[0].values()\n",
    "\n",
    "# Syn\n",
    "var_name = random.choice(list(lab_syn.keys()))\n",
    "gt = lab_syn[var_name]\n",
    "question = SL.questions_syn[0].format(varname=var_name)\n",
    "prompt_syn = SL.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                problem=p_syn, \n",
    "                                question=question)\n",
    "print(prompt_syn)\n",
    "print(\"Answer:\", gt)\n",
    "\n",
    "print(\"=\"*30)\n",
    "# Nat\n",
    "agent_name = random.choice(list(lab_nat.keys()))\n",
    "object_name = random.choice(list(lab_nat[agent_name].keys()))\n",
    "gt = lab_nat[agent_name][object_name]\n",
    "question = SL.questions_nat[0].format(varname=object_name, agentname=agent_name)\n",
    "prompt_nat = SL.user_cot.format(prefix=\"\",\n",
    "                                problem=p_nat,\n",
    "                                question=question)\n",
    "print(prompt_nat)\n",
    "print(\"Answer:\", gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critical Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prompts\n",
    "import json \n",
    "import random\n",
    "from codesim.prompt import CriticalPath as CP\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/CriticalPath/n_ops-20_n_vars-4_len_critical_path-10_batch-1.json\"))\n",
    "p_syn, p_nat, lab_syn, lab_nat = data[0].values()\n",
    "\n",
    "# Syn\n",
    "var_name = random.choice(list(lab_syn.keys()))\n",
    "gt = lab_syn[var_name]\n",
    "question = CP.questions_syn[0].format(varname=var_name)\n",
    "prompt_syn = CP.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                problem=p_syn, \n",
    "                                question=question)\n",
    "print(prompt_syn)\n",
    "print(\"Answer:\", gt)\n",
    "\n",
    "print(\"=\"*30)\n",
    "# Nat\n",
    "agent_name = random.choice(list(lab_nat.keys()))  # can sample here\n",
    "gt = lab_nat[agent_name]\n",
    "question = CP.questions_nat[0].format(agentname=agent_name)\n",
    "prompt_nat = CP.user_cot.format(prefix=\"\",\n",
    "                                problem=p_nat,\n",
    "                                question=question)\n",
    "print(prompt_nat)\n",
    "print(\"Answer:\", gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prompts\n",
    "import json \n",
    "from codesim.prompt import ParallelPaths as PP\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/ParallelPaths/n_ops-20_n_vars-3_n_instances-2_batch-1.json\"))\n",
    "p_syn, p_nat, lab_syn, lab_nat = data[0].values()\n",
    "\n",
    "# Syn\n",
    "var_names = list(lab_syn.keys())\n",
    "gt = list(lab_syn.values())\n",
    "question = PP.questions_syn[0].format(varnames=\", \".join(var_names))\n",
    "prompt_syn = PP.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                problem=p_syn, \n",
    "                                question=question)\n",
    "print(prompt_syn)\n",
    "print(\"Answer:\", gt)\n",
    "\n",
    "print(\"=\"*30)\n",
    "# Nat\n",
    "agent_names = list(lab_nat.keys())\n",
    "object_names = list(lab_nat[agent_names[0]].keys())\n",
    "gt = list(lab_syn.values())\n",
    "question = PP.questions_nat[0].format(varnames=object_names,\n",
    "                                      agentnames=agent_names)\n",
    "prompt_nat = PP.user_cot.format(prefix=\"\",\n",
    "                                problem=p_nat,\n",
    "                                question=question)\n",
    "print(prompt_nat)\n",
    "print(\"Answer:\", gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here's a list of numbers. x = [2, 57, 75, 73, 15, 4, 71, 30, 94, 62]\n",
      "\n",
      "Simulate the following algorithm with the list of numbers as input:\n",
      "\n",
      "def f(arr):\n",
      "    n = len(arr)\n",
      "    for j in range(1, n):\n",
      "        val = arr[j]\n",
      "        i = j - 1\n",
      "        while i >= 0 and val < arr[i]:\n",
      "            arr[i + 1] = arr[i]\n",
      "            i -= 1\n",
      "        arr[i + 1] = val\n",
      "    return arr\n",
      "\n",
      "When the function terminates, what is the value of the x[5]?\n",
      "Think step by step and provide the numerical answer between <answer></answer> tags.\n",
      "For example, reply with <answer>1</answer> if the answer is 1.\n",
      "\n",
      "Answer: 62\n",
      "==============================\n",
      "\n",
      "One has the following 10 objects: ['obj-0', 'obj-1', 'obj-2', 'obj-3', 'obj-4', 'obj-5', 'obj-6', 'obj-7', 'obj-8', 'obj-9'].\n",
      "\n",
      "This is the weight of each object in Kg: {'obj-0': 2, 'obj-1': 57, 'obj-2': 75, 'obj-3': 73, 'obj-4': 15, 'obj-5': 4, 'obj-6': 71, 'obj-7': 30, 'obj-8': 94, 'obj-9': 62}.\n",
      "\n",
      "\n",
      "What is the value of 5-th most heavy object?\n",
      "Think step by step and provide the numerical answer between <answer></answer> tags.\n",
      "For example, reply with <answer>1</answer> if the answer is 1.\n",
      "\n",
      "Answer: obj-9\n"
     ]
    }
   ],
   "source": [
    "# Test the prompts\n",
    "import json \n",
    "from codesim.prompt import Sort\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/Sort/n_vars-10_ascending-True_batch-1.json\"))\n",
    "p_syn, p_nat, lab_syn, lab_nat = data[1].values()\n",
    "\n",
    "# Syn\n",
    "gt = lab_syn[\"label\"]\n",
    "position = lab_syn[\"position\"]\n",
    "ascending = lab_syn[\"ascending\"]\n",
    "question = Sort.questions_syn[0].format(k=position)\n",
    "prompt_syn = Sort.user_cot.format(prefix=\"\", \n",
    "                                problem=p_syn, \n",
    "                                question=question)\n",
    "print(prompt_syn)\n",
    "print(\"Answer:\", gt)\n",
    "\n",
    "print(\"=\"*30)\n",
    "# Nat\n",
    "# object_name = list(lab_nat[agent_name].keys())  # same...\n",
    "gt = lab_nat[\"label\"]\n",
    "question = Sort.questions_nat[0].format(k=position, biggest_smallest= \"most heavy\" if ascending else \"most light\")\n",
    "prompt_nat = Sort.user_cot.format(prefix=\"\",\n",
    "                                problem=p_nat,\n",
    "                                question=question)\n",
    "print(prompt_nat)\n",
    "print(\"Answer:\", gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's some code:\n",
      "n_0=0; n_1=0; n_2=0; n_3=0\n",
      "for _ in range(10):\n",
      "\tn_0 += 1\n",
      "\tfor _ in range(4):\n",
      "\t\tn_1 += 1\n",
      "\tfor _ in range(9):\n",
      "\t\tn_2 += 1\n",
      "\t\tfor _ in range(7):\n",
      "\t\t\tn_3 += 1\n",
      "\n",
      "What is the value of n_3 at the end of the computation?\n",
      "Think step by step and provide the numerical answer between <answer></answer> tags.\n",
      "For example, reply with <answer>1</answer> if the answer is 1.\n",
      "\n",
      "Answer: 630\n",
      "\n",
      "Here's a situation.\n",
      "There are 10 obj-0 in obj-gen.\n",
      "There are 4 nobj-3 in obj-0.\n",
      "There are 9 obj-2 in obj-0.\n",
      "There are 7 nobj-1 in obj-2.\n",
      "\n",
      "How many obj-3 are in a obj-gen?\n",
      "Think step by step and provide the numerical answer between <answer></answer> tags.\n",
      "For example, reply with <answer>1</answer> if the answer is 1.\n",
      "\n",
      "Answer: 630\n"
     ]
    }
   ],
   "source": [
    "# Test the prompts\n",
    "import json \n",
    "from codesim.prompt import Loops\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/Loops/n_loops-4_n_noisy_loops-2_min_loop_length-2_max_loop-10_batch-1.json\"))\n",
    "p_syn, p_nat, lab_syn, lab_nat = data[0].values()\n",
    "\n",
    "# Syn\n",
    "first_key = list(lab_syn.keys())[0]\n",
    "gt = lab_syn[first_key]\n",
    "question = Loops.questions_syn[0].format(varname=first_key)\n",
    "prompt_syn = Loops.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                problem=p_syn, \n",
    "                                question=question)\n",
    "print(prompt_syn)\n",
    "print(\"Answer:\", gt)\n",
    "\n",
    "# Nat\n",
    "key_val = list(lab_nat.keys())[0]\n",
    "content, box = key_val.split(\" in \")\n",
    "gt = lab_nat[key_val]\n",
    "question = Loops.questions_nat[0].format(varname=content, varname_origin=box)\n",
    "prompt_nat = Loops.user_cot.format(prefix=\"\",\n",
    "                                problem=p_nat,\n",
    "                                question=question)\n",
    "print(prompt_nat)\n",
    "print(\"Answer:\", gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prompts\n",
    "import json \n",
    "from codesim.prompt import Boxes\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/boxes/num_boxes-7-max_items_per_box-3-batch-1.json\"))\n",
    "p_syn, p_nat, lab_syn, lab_nat = data[10].values()\n",
    "\n",
    "# Syn\n",
    "first_key = list(lab_syn.keys())[0]\n",
    "question = Boxes.questions_syn[0].format(varname=f\"x{first_key}\")\n",
    "prompt_syn = Boxes.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                   problem=p_syn, \n",
    "                                   question=question,\n",
    "                                   example_answer=repr('{9, 5}'))\n",
    "print(prompt_syn)\n",
    "print(\"Answer:\", lab_syn[first_key])\n",
    "\n",
    "# Nat\n",
    "first_key = list(lab_nat.keys())[0]\n",
    "question = Boxes.questions_nat[0].format(varname=f\"box {first_key}\")\n",
    "prompt_nat = Boxes.user_cot.format(prefix=\"\",\n",
    "                                problem=p_nat,\n",
    "                                question=question,\n",
    "                                example_answer=repr('{brain, disk}'))\n",
    "print(prompt_nat)\n",
    "print(\"Answer:\", lab_nat[first_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test exec-time SambaNova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from codesim.prompt import StraightLine as SL\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=\"your-key\",\n",
    "    base_url=\"https://api.sambanova.ai/v1\",\n",
    ")\n",
    "\n",
    "def call(x:str) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model='Meta-Llama-3.1-405B-Instruct',\n",
    "        messages=[{\"role\":\"system\",\"content\":\"You are a helpful assistant\"},{\"role\":\"user\",\"content\":x}],\n",
    "        temperature =  0.1,\n",
    "        top_p = 0.1\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/StraightLine/n_ops-20_n_vars-3_n_instances-2_batch-1.json\"))\n",
    "\n",
    "for idx, d in tqdm(enumerate(data)):\n",
    "    p_syn, p_nat, lab_syn, lab_nat = d.values()\n",
    "    var_name = list(lab_syn.keys())[0]  # can sample here\n",
    "    gt = lab_syn[var_name]\n",
    "    question = SL.questions_syn[0].format(varname=var_name)\n",
    "    prompt_syn = SL.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                    problem=p_syn, \n",
    "                                    question=question)\n",
    "    responses = {}\n",
    "    try:\n",
    "        responses[idx] = { \"prompt\": prompt_syn,\n",
    "                           \"response\": call(prompt_syn),\n",
    "                           \"gt\": gt\n",
    "                        }\n",
    "    except:\n",
    "        sleep(5)\n",
    "        \n",
    "json.dump(responses, open(\"responses.json\", \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesim.problem import StraightLine \n",
    "\n",
    "n_vars = 3; n_instances = 2\n",
    "for n_ops in [10, 20, 30, 40, 50]:\n",
    "    gen = StraightLine(n_ops=n_ops, \n",
    "                    n_vars=n_vars,\n",
    "                    n_instances=n_instances)\n",
    "\n",
    "    # Generate and save 3 batches of 30 problems each\n",
    "    for i in range(3):\n",
    "        gen.generate_data(n_programs=30)\n",
    "        gen.to_file(suffix=\"batch-\" + str(i+1))\n",
    "        gen.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesim.problem import CriticalPath \n",
    "\n",
    "n_vars = 6; len_critical_path =5\n",
    "for n_ops in [10, 20, 30, 40, 50]:\n",
    "    gen = CriticalPath(n_ops=n_ops, \n",
    "                       n_vars=n_vars,\n",
    "                       len_critical_path=len_critical_path)\n",
    "\n",
    "    # Generate and save 3 batches of 30 problems each\n",
    "    for i in range(3):\n",
    "        gen.generate_data(n_programs=30)\n",
    "        gen.to_file(suffix=\"batch-\" + str(i+1))\n",
    "        gen.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesim.problem import ParallelPaths \n",
    "\n",
    "n_vars = 3; n_instances = 2\n",
    "for n_ops in [10, 20, 30, 40, 50]:\n",
    "    gen = ParallelPaths(n_ops=n_ops, \n",
    "                        n_vars=n_vars,\n",
    "                        n_instances=n_instances)\n",
    "\n",
    "    # Generate and save 3 batches of 30 problems each\n",
    "    for i in range(3):\n",
    "        gen.generate_data(n_programs=30)\n",
    "        gen.to_file(suffix=\"batch-\" + str(i+1))\n",
    "        gen.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesim.problem import Loops \n",
    "\n",
    "n_loops = [n for n in range(3, 11)]\n",
    "n_noisy_loops = [int(n/2) for n in n_loops]\n",
    "for n,m in zip(n_loops, n_noisy_loops):\n",
    "    gen = Loops(n_loops=n, \n",
    "                n_noisy_loops=m,\n",
    "                min_loop_length=2,\n",
    "                max_loop_length=10)\n",
    "\n",
    "    # Generate and save 3 batches of 30 problems each\n",
    "    for i in range(3):\n",
    "        gen.generate_data(n_programs=30)\n",
    "        gen.to_file(suffix=\"batch-\" + str(i+1))\n",
    "        gen.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesim.problem import Sort \n",
    "\n",
    "for n_vars in [10, 20, 30, 40, 50]:\n",
    "    # Ascending\n",
    "    gen = Sort(n_vars=n_vars,\n",
    "            ascending=True)\n",
    "\n",
    "    # Generate and save 3 batches of 30 problems each\n",
    "    for i in range(3):\n",
    "        gen.generate_data(n_programs=30)\n",
    "        gen.to_file(suffix=\"batch-\" + str(i+1))\n",
    "        gen.reset()\n",
    "    \n",
    "    # Descending    \n",
    "    gen = Sort(n_vars=n_vars,\n",
    "            ascending=False)\n",
    "\n",
    "    # Generate and save 3 batches of 30 problems each\n",
    "    for i in range(3):\n",
    "        gen.generate_data(n_programs=30)\n",
    "        gen.to_file(suffix=\"batch-\" + str(i+1))\n",
    "        gen.reset()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Namespace(object_vocabulary_file='data/objects_with_bnc_frequency.csv', disjoint_object_vocabulary_file=None, disjoint_object_splits='test', output_dir='data/boxes', seed=2255, num_boxes=7, expected_num_items_per_box=1, max_items_per_box=1, num_samples=30, num_operations=10, disjoint_numops=False, zero_shot=False, include_modifiers='never', omit_modifiers_in_ops='never', alternative_forms='never', rarify=False, all_contents_operation=False)\n",
      "finished sampling 60 sequences of length 10.\n",
      "Saved outputs to data/boxes.\n",
      "Namespace(object_vocabulary_file='data/objects_with_bnc_frequency.csv', disjoint_object_vocabulary_file=None, disjoint_object_splits='test', output_dir='data/boxes', seed=2255, num_boxes=7, expected_num_items_per_box=1, max_items_per_box=3, num_samples=30, num_operations=10, disjoint_numops=False, zero_shot=False, include_modifiers='never', omit_modifiers_in_ops='never', alternative_forms='never', rarify=False, all_contents_operation=False)\n",
      "finished sampling 60 sequences of length 10.\n",
      "Saved outputs to data/boxes.\n",
      "Namespace(object_vocabulary_file='data/objects_with_bnc_frequency.csv', disjoint_object_vocabulary_file=None, disjoint_object_splits='test', output_dir='data/boxes', seed=2255, num_boxes=7, expected_num_items_per_box=1, max_items_per_box=5, num_samples=30, num_operations=10, disjoint_numops=False, zero_shot=False, include_modifiers='never', omit_modifiers_in_ops='never', alternative_forms='never', rarify=False, all_contents_operation=False)\n",
      "finished sampling 60 sequences of length 10.\n",
      "Saved outputs to data/boxes.\n",
      "Namespace(object_vocabulary_file='data/objects_with_bnc_frequency.csv', disjoint_object_vocabulary_file=None, disjoint_object_splits='test', output_dir='data/boxes', seed=2255, num_boxes=7, expected_num_items_per_box=1, max_items_per_box=7, num_samples=30, num_operations=10, disjoint_numops=False, zero_shot=False, include_modifiers='never', omit_modifiers_in_ops='never', alternative_forms='never', rarify=False, all_contents_operation=False)\n",
      "finished sampling 60 sequences of length 10.\n",
      "Saved outputs to data/boxes.\n",
      "Namespace(object_vocabulary_file='data/objects_with_bnc_frequency.csv', disjoint_object_vocabulary_file=None, disjoint_object_splits='test', output_dir='data/boxes', seed=2255, num_boxes=7, expected_num_items_per_box=1, max_items_per_box=9, num_samples=30, num_operations=10, disjoint_numops=False, zero_shot=False, include_modifiers='never', omit_modifiers_in_ops='never', alternative_forms='never', rarify=False, all_contents_operation=False)\n",
      "finished sampling 60 sequences of length 10.\n",
      "Saved outputs to data/boxes.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from codesim.kim_schuster import real_main\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "for n_items in [1, 3, 5, 7, 9]:\n",
    "    # simulate CLI run\n",
    "    sys.argv = [\"codesim/kim_schuster.py\", \n",
    "                \"--max_items_per_box\", f\"{n_items}\",\n",
    "                \"--num_samples\", \"30\"]\n",
    "\n",
    "    real_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Straight Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting the Tests for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from codesim.experiment import main as start_experiment\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# simulate CLI run\n",
    "sys.argv = [\"codesim/experiment.py\", \n",
    "            \"--dataset_idx\", \"0\",\n",
    "            \"--model\", \"gpt-4o-mini\",\n",
    "            \"--operation\", \"kim-schuster\"]\n",
    "\n",
    "start_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from codesim.experiment import main as start_experiment\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# simulate CLI run\n",
    "sys.argv = [\"codesim/experiment.py\", \n",
    "            \"--dataset_path\", \"data/StraightLine/n_ops-20_n_vars-3_n_instances-2_batch-1.json\",\n",
    "            \"--model\", \"gpt-4o-mini\",\n",
    "            \"--operation\", \"straight-line\"]\n",
    "\n",
    "start_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from codesim.experiment import main as start_experiment\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# simulate CLI run\n",
    "sys.argv = [\"codesim/experiment.py\", \n",
    "            \"--dataset_path\", \"data/StraightLine/n_ops-20_n_vars-3_n_instances-2_batch-1.json\",\n",
    "            \"--model\", \"gpt-4o-mini\",\n",
    "            \"--operation\", \"sorting\"]\n",
    "\n",
    "start_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
