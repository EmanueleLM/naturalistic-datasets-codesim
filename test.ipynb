{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prompts\n",
    "import json \n",
    "from codesim.prompt import StraightLine as SL\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/StraightLine/n_ops-20_n_vars-3_n_instances-2_batch-1.json\"))\n",
    "p_syn, p_nat, lab_syn, lab_nat = data[0].values()\n",
    "\n",
    "# Syn\n",
    "var_name = list(lab_syn.keys())[0]  # can sample here\n",
    "gt = lab_syn[var_name]\n",
    "question = SL.questions_syn[0].format(varname=var_name)\n",
    "prompt_syn = SL.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                problem=p_syn, \n",
    "                                question=question)\n",
    "print(prompt_syn)\n",
    "\n",
    "print(\"=\"*30)\n",
    "# Nat\n",
    "agent_name = list(lab_nat.keys())[0]  # can sample here\n",
    "object_name = list(lab_nat[agent_name].keys())[0]  # same...\n",
    "gt = lab_nat[agent_name][object_name]\n",
    "question = SL.questions_nat[0].format(varname=object_name, agentname=agent_name)\n",
    "prompt_nat = SL.user_cot.format(prefix=\"\",\n",
    "                                problem=p_nat,\n",
    "                                question=question)\n",
    "print(prompt_nat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critical Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (2126331429.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    idx_label = random.sample(list(lab_syn.keys()), 1)var_name = list(lab_syn.keys())[0idx_label  # can sample here\u001b[0m\n\u001b[0m                                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "# Test the prompts\n",
    "import json \n",
    "import random\n",
    "from codesim.prompt import CriticalPath as CP\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/CriticalPath/n_ops-20_n_vars-4_len_critical_path-10_batch-1.json\"))\n",
    "p_syn, p_nat, lab_syn, lab_nat = data[0].values()\n",
    "\n",
    "# Syn\n",
    "idx_label = random.sample(list(lab_syn.keys()), 1)var_name = list(lab_syn.keys())[0idx_label  # can sample here\n",
    "gt = lab_syn[var_name]\n",
    "question = CP.questions_syn[0].format(varname=var_name)\n",
    "prompt_syn = CP.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                problem=p_syn, \n",
    "                                question=question)\n",
    "print(prompt_syn)\n",
    "\n",
    "print(\"=\"*30)\n",
    "# Nat\n",
    "agent_name = list(lab_nat.keys())[0]  # can sample here\n",
    "gt = lab_nat[agent_name]\n",
    "question = CP.questions_nat[0].format(agentname=agent_name)\n",
    "prompt_nat = CP.user_cot.format(prefix=\"\",\n",
    "                                problem=p_nat,\n",
    "                                question=question)\n",
    "print(prompt_nat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prompts\n",
    "import json \n",
    "from codesim.prompt import ParallelPaths as PP\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/ParallelPaths/n_ops-20_n_vars-3_n_instances-2_batch-1.json\"))\n",
    "p_syn, p_nat, lab_syn, lab_nat = data[0].values()\n",
    "\n",
    "# Syn\n",
    "var_names = list(lab_syn.keys())  # can sample here\n",
    "# gt = lab_syn[var_name]\n",
    "question = PP.questions_syn[0].format(varnames=\", \".join(var_names))\n",
    "prompt_syn = PP.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                problem=p_syn, \n",
    "                                question=question)\n",
    "print(prompt_syn)\n",
    "\n",
    "print(\"=\"*30)\n",
    "# Nat\n",
    "# object_name = list(lab_nat[agent_name].keys())  # same...\n",
    "# gt = lab_nat[agent_name][object_name]\n",
    "question = PP.questions_nat[0]\n",
    "prompt_nat = PP.user_cot.format(prefix=\"\",\n",
    "                                problem=p_nat,\n",
    "                                question=question)\n",
    "print(prompt_nat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prompts\n",
    "import json \n",
    "from codesim.prompt import Sort\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/ParallelPaths/n_vars-10_ascending-True_batch-1.json\"))\n",
    "p_syn, p_nat, lab_syn, lab_nat = data[0].values()\n",
    "\n",
    "# Syn\n",
    "position = lab_syn[\"position\"]\n",
    "ascending = lab_syn[\"ascending\"]\n",
    "question = Sort.questions_syn[0].format(k=position, ascending= \"biggest\" if ascending else \"smallest\")\n",
    "prompt_syn = Sort.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                problem=p_syn, \n",
    "                                question=question)\n",
    "print(prompt_syn)\n",
    "# Nat\n",
    "# object_name = list(lab_nat[agent_name].keys())  # same...\n",
    "# gt = lab_nat[agent_name][object_name]\n",
    "question = Sort.questions_nat[0]\n",
    "prompt_nat = Sort.user_cot.format(prefix=\"\",\n",
    "                                problem=p_nat,\n",
    "                                question=question)\n",
    "print(prompt_nat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Test exec-time SambaNova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from codesim.prompt import StraightLine as SL\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=\"380072e2-1a5e-4d75-b7a7-d657a457c416\",\n",
    "    base_url=\"https://api.sambanova.ai/v1\",\n",
    ")\n",
    "\n",
    "def call(x:str) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model='Meta-Llama-3.1-405B-Instruct',\n",
    "        messages=[{\"role\":\"system\",\"content\":\"You are a helpful assistant\"},{\"role\":\"user\",\"content\":x}],\n",
    "        temperature =  0.1,\n",
    "        top_p = 0.1\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/StraightLine/n_ops-20_n_vars-3_n_instances-2_batch-1.json\"))\n",
    "\n",
    "for idx, d in tqdm(enumerate(data)):\n",
    "    p_syn, p_nat, lab_syn, lab_nat = d.values()\n",
    "    var_name = list(lab_syn.keys())[0]  # can sample here\n",
    "    gt = lab_syn[var_name]\n",
    "    question = SL.questions_syn[0].format(varname=var_name)\n",
    "    prompt_syn = SL.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                    problem=p_syn, \n",
    "                                    question=question)\n",
    "    responses = {}\n",
    "    try:\n",
    "        responses[idx] = { \"prompt\": prompt_syn,\n",
    "                           \"response\": call(prompt_syn),\n",
    "                           \"gt\": gt\n",
    "                        }\n",
    "    except:\n",
    "        sleep(5)\n",
    "        \n",
    "json.dump(responses, open(\"responses.json\", \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Retrieve and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesim.problem import StraightLine \n",
    "\n",
    "gen = StraightLine(n_ops=20, \n",
    "                   n_vars=3,\n",
    "                   n_instances=2)\n",
    "\n",
    "# Generate and save 3 batches of 30 problems each\n",
    "for i in range(3):\n",
    "    gen.generate_data(n_programs=30)\n",
    "    gen.to_file(suffix=\"batch-\" + str(i+1))\n",
    "    gen.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesim.problem import CriticalPath \n",
    "\n",
    "gen = CriticalPath(n_ops=20, \n",
    "                   n_vars=4,\n",
    "                   len_critical_path=10)\n",
    "\n",
    "# Generate and save 3 batches of 30 problems each\n",
    "for i in range(3):\n",
    "    gen.generate_data(n_programs=30)\n",
    "    gen.to_file(suffix=\"batch-\" + str(i+1))\n",
    "    gen.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesim.problem import ParallelPaths \n",
    "\n",
    "gen = ParallelPaths(n_ops=20, \n",
    "                    n_vars=3,\n",
    "                    n_instances=2)\n",
    "\n",
    "# Generate and save 3 batches of 30 problems each\n",
    "for i in range(3):\n",
    "    gen.generate_data(n_programs=30)\n",
    "    gen.to_file(suffix=\"batch-\" + str(i+1))\n",
    "    gen.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesim.problem import Loops \n",
    "\n",
    "gen = Loops(n_loops=5, \n",
    "            n_noisy_loops=2,\n",
    "            min_loop_length=3,\n",
    "            max_loop_length=5)\n",
    "\n",
    "# Generate and save 3 batches of 30 problems each\n",
    "for i in range(3):\n",
    "    gen.generate_data(n_programs=30)\n",
    "    gen.to_file(suffix=\"batch-\" + str(i+1))\n",
    "    gen.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesim.problem import Sort \n",
    "\n",
    "gen = Sort(n_vars=10,\n",
    "           ascending=True)\n",
    "\n",
    "# Generate and save 3 batches of 30 problems each\n",
    "for i in range(3):\n",
    "    gen.generate_data(n_programs=30)\n",
    "    gen.to_file(suffix=\"batch-\" + str(i+1))\n",
    "    gen.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from codesim.kim_schuster import real_main\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# simulate CLI run\n",
    "sys.argv = [\"codesim/kim_schuster.py\", \n",
    "            \"--max_items_per_box\", \"3\",\n",
    "            \"--num_samples\", \"30\"]\n",
    "\n",
    "real_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Straight Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
