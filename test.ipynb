{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Straight Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prompts\n",
    "import json \n",
    "import random\n",
    "from codesim.prompt import StraightLine as SL\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/StraightLine/n_ops-20_n_vars-3_n_instances-2_batch-1.json\"))\n",
    "p_syn, p_nat, lab_syn, lab_nat = data[0].values()\n",
    "\n",
    "# Syn\n",
    "var_name = random.choice(list(lab_syn.keys()))\n",
    "gt = lab_syn[var_name]\n",
    "question = SL.questions_syn[0].format(varname=var_name)\n",
    "prompt_syn = SL.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                problem=p_syn, \n",
    "                                question=question)\n",
    "print(prompt_syn)\n",
    "\n",
    "print(\"=\"*30)\n",
    "# Nat\n",
    "agent_name = random.choice(list(lab_nat.keys()))\n",
    "object_name = random.choice(list(lab_nat[agent_name].keys()))\n",
    "gt = lab_nat[agent_name][object_name]\n",
    "question = SL.questions_nat[0].format(varname=object_name, agentname=agent_name)\n",
    "prompt_nat = SL.user_cot.format(prefix=\"\",\n",
    "                                problem=p_nat,\n",
    "                                question=question)\n",
    "print(prompt_nat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critical Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prompts\n",
    "import json \n",
    "import random\n",
    "from codesim.prompt import CriticalPath as CP\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/CriticalPath/n_ops-20_n_vars-4_len_critical_path-10_batch-1.json\"))\n",
    "p_syn, p_nat, lab_syn, lab_nat = data[0].values()\n",
    "\n",
    "# Syn\n",
    "var_name = random.choice(list(lab_syn.keys()))\n",
    "gt = lab_syn[var_name]\n",
    "question = CP.questions_syn[0].format(varname=var_name)\n",
    "prompt_syn = CP.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                problem=p_syn, \n",
    "                                question=question)\n",
    "print(prompt_syn)\n",
    "\n",
    "print(\"=\"*30)\n",
    "# Nat\n",
    "agent_name = random.choice(list(lab_nat.keys()))  # can sample here\n",
    "gt = lab_nat[agent_name]\n",
    "question = CP.questions_nat[0].format(agentname=agent_name)\n",
    "prompt_nat = CP.user_cot.format(prefix=\"\",\n",
    "                                problem=p_nat,\n",
    "                                question=question)\n",
    "print(prompt_nat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prompts\n",
    "import json \n",
    "from codesim.prompt import ParallelPaths as PP\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/ParallelPaths/n_ops-20_n_vars-3_n_instances-2_batch-1.json\"))\n",
    "p_syn, p_nat, lab_syn, lab_nat = data[0].values()\n",
    "\n",
    "# Syn\n",
    "var_names = list(lab_syn.keys())\n",
    "gt = list(lab_syn.values())\n",
    "question = PP.questions_syn[0].format(varnames=\", \".join(var_names))\n",
    "prompt_syn = PP.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                problem=p_syn, \n",
    "                                question=question)\n",
    "print(prompt_syn)\n",
    "\n",
    "print(\"=\"*30)\n",
    "# Nat\n",
    "agent_names = list(lab_nat.keys())\n",
    "object_names = list(lab_nat[agent_names[0]].keys())\n",
    "gt = list(lab_syn.values())\n",
    "question = PP.questions_nat[0].format(varnames=object_names,\n",
    "                                      agentnames=agent_names)\n",
    "prompt_nat = PP.user_cot.format(prefix=\"\",\n",
    "                                problem=p_nat,\n",
    "                                question=question)\n",
    "print(prompt_nat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prompts\n",
    "import json \n",
    "from codesim.prompt import Sort\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/Sort/n_vars-10_ascending-True_batch-1.json\"))\n",
    "p_syn, p_nat, lab_syn, lab_nat = data[0].values()\n",
    "\n",
    "# Syn\n",
    "position = lab_syn[\"position\"]\n",
    "ascending = lab_syn[\"ascending\"]\n",
    "question = Sort.questions_syn[0].format(k=position, heavy = \"heavy\" if ascending else \"light\")\n",
    "prompt_syn = Sort.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                problem=p_syn, \n",
    "                                question=question)\n",
    "print(prompt_syn)\n",
    "# Nat\n",
    "# object_name = list(lab_nat[agent_name].keys())  # same...\n",
    "# gt = lab_nat[agent_name][object_name]\n",
    "question = Sort.questions_nat[0].format(k=position, biggest_smallest= \"biggest\" if ascending else \"smallest\")\n",
    "prompt_nat = Sort.user_cot.format(prefix=\"\",\n",
    "                                problem=p_nat,\n",
    "                                question=question)\n",
    "print(prompt_nat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prompts\n",
    "import json \n",
    "from codesim.prompt import Loops\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/Loops/n_loops-5_n_noisy_loops-2_min_loop_length-3_max_loop-5_batch-1.json\"))\n",
    "p_syn, p_nat, lab_syn, lab_nat = data[0].values()\n",
    "\n",
    "# Syn\n",
    "first_key = list(lab_syn.keys())[0]\n",
    "question = Loops.questions_syn[0].format(varname=first_key)\n",
    "prompt_syn = Loops.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                problem=p_syn, \n",
    "                                question=question)\n",
    "print(prompt_syn)\n",
    "# Nat\n",
    "key_val = list(lab_nat.keys())[0]\n",
    "content, box = key_val.split(\" in \")\n",
    "# object_name = list(lab_nat[agent_name].keys())  # same...\n",
    "# gt = lab_nat[agent_name][object_name]\n",
    "question = Loops.questions_nat[0].format(varname=content, varname_origin=box)\n",
    "prompt_nat = Loops.user_cot.format(prefix=\"\",\n",
    "                                problem=p_nat,\n",
    "                                question=question)\n",
    "print(prompt_nat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prompts\n",
    "import json \n",
    "from codesim.prompt import Boxes\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/boxes/batch-1.json\"))\n",
    "p_syn, p_nat, lab_syn, lab_nat = data[0].values()\n",
    "\n",
    "# Syn\n",
    "first_key = list(lab_syn.keys())[0]\n",
    "question = Boxes.questions_syn[0].format(varname=f\"x{first_key}\")\n",
    "prompt_syn = Boxes.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                problem=p_syn, \n",
    "                                question=question)\n",
    "print(prompt_syn)\n",
    "\n",
    "# Nat\n",
    "first_key = list(lab_nat.keys())[0]\n",
    "# object_name = list(lab_nat[agent_name].keys())  # same...\n",
    "# gt = lab_nat[agent_name][object_name]\n",
    "question = Boxes.questions_nat[0].format(varname=f\"box {first_key}\")\n",
    "prompt_nat = Boxes.user_cot.format(prefix=\"\",\n",
    "                                problem=p_nat,\n",
    "                                question=question)\n",
    "print(prompt_nat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Test exec-time SambaNova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from codesim.prompt import StraightLine as SL\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=\"380072e2-1a5e-4d75-b7a7-d657a457c416\",\n",
    "    base_url=\"https://api.sambanova.ai/v1\",\n",
    ")\n",
    "\n",
    "def call(x:str) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model='Meta-Llama-3.1-405B-Instruct',\n",
    "        messages=[{\"role\":\"system\",\"content\":\"You are a helpful assistant\"},{\"role\":\"user\",\"content\":x}],\n",
    "        temperature =  0.1,\n",
    "        top_p = 0.1\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/StraightLine/n_ops-20_n_vars-3_n_instances-2_batch-1.json\"))\n",
    "\n",
    "for idx, d in tqdm(enumerate(data)):\n",
    "    p_syn, p_nat, lab_syn, lab_nat = d.values()\n",
    "    var_name = list(lab_syn.keys())[0]  # can sample here\n",
    "    gt = lab_syn[var_name]\n",
    "    question = SL.questions_syn[0].format(varname=var_name)\n",
    "    prompt_syn = SL.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                    problem=p_syn, \n",
    "                                    question=question)\n",
    "    responses = {}\n",
    "    try:\n",
    "        responses[idx] = { \"prompt\": prompt_syn,\n",
    "                           \"response\": call(prompt_syn),\n",
    "                           \"gt\": gt\n",
    "                        }\n",
    "    except:\n",
    "        sleep(5)\n",
    "        \n",
    "json.dump(responses, open(\"responses.json\", \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Retrieve and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesim.problem import StraightLine \n",
    "\n",
    "gen = StraightLine(n_ops=20, \n",
    "                   n_vars=3,\n",
    "                   n_instances=2)\n",
    "\n",
    "# Generate and save 3 batches of 30 problems each\n",
    "for i in range(3):\n",
    "    gen.generate_data(n_programs=30)\n",
    "    gen.to_file(suffix=\"batch-\" + str(i+1))\n",
    "    gen.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesim.problem import CriticalPath \n",
    "\n",
    "gen = CriticalPath(n_ops=20, \n",
    "                   n_vars=4,\n",
    "                   len_critical_path=10)\n",
    "\n",
    "# Generate and save 3 batches of 30 problems each\n",
    "for i in range(3):\n",
    "    gen.generate_data(n_programs=30)\n",
    "    gen.to_file(suffix=\"batch-\" + str(i+1))\n",
    "    gen.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesim.problem import ParallelPaths \n",
    "\n",
    "gen = ParallelPaths(n_ops=20, \n",
    "                    n_vars=3,\n",
    "                    n_instances=2)\n",
    "\n",
    "# Generate and save 3 batches of 30 problems each\n",
    "for i in range(3):\n",
    "    gen.generate_data(n_programs=30)\n",
    "    gen.to_file(suffix=\"batch-\" + str(i+1))\n",
    "    gen.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesim.problem import Loops \n",
    "\n",
    "gen = Loops(n_loops=5, \n",
    "            n_noisy_loops=2,\n",
    "            min_loop_length=3,\n",
    "            max_loop_length=5)\n",
    "\n",
    "# Generate and save 3 batches of 30 problems each\n",
    "for i in range(3):\n",
    "    gen.generate_data(n_programs=30)\n",
    "    gen.to_file(suffix=\"batch-\" + str(i+1))\n",
    "    gen.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesim.problem import Sort \n",
    "\n",
    "gen = Sort(n_vars=10,\n",
    "           ascending=True)\n",
    "\n",
    "# Generate and save 3 batches of 30 problems each\n",
    "for i in range(3):\n",
    "    gen.generate_data(n_programs=30)\n",
    "    gen.to_file(suffix=\"batch-\" + str(i+1))\n",
    "    gen.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from codesim.kim_schuster import real_main\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# simulate CLI run\n",
    "sys.argv = [\"codesim/kim_schuster.py\", \n",
    "            \"--max_items_per_box\", \"3\",\n",
    "            \"--num_samples\", \"30\"]\n",
    "\n",
    "real_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Straight Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting the Tests for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
  "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e68649c88f4aad819c183b155f3f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113290611112664, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/flecart/Desktop/work/naturalistic-datasets-codesim/wandb/run-20250115_132922-4imax5rn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/giospadaccini-eth/codesim/runs/4imax5rn' target=\"_blank\">frosty-bush-8</a></strong> to <a href='https://wandb.ai/giospadaccini-eth/codesim' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/giospadaccini-eth/codesim' target=\"_blank\">https://wandb.ai/giospadaccini-eth/codesim</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/giospadaccini-eth/codesim/runs/4imax5rn' target=\"_blank\">https://wandb.ai/giospadaccini-eth/codesim/runs/4imax5rn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation: kim-schuster\n",
      "Dataset Path: data/boxes/batch-1.json\n",
      "Objects Sampled: {0: 'note', 1: 'cigarette', 2: 'bowl', 3: 'book', 4: 'block', 5: 'dish', 6: 'boat', 7: 'book', 8: 'game', 9: 'car'}\n",
      "The code provided initializes several sets (x0, x1, x2, x3, x4, x5, x6) with specific integer values. However, there are no operations or modifications applied to these sets in the code snippet you provided. Therefore, the content of x0 remains unchanged throughout the computation.\n",
      "\n",
      "At the end of the computation, the content of x0 is still {37}.\n",
      "\n",
      "Thus, the answer is:\n",
      "\n",
      "<answer>37</answer>\n",
      "To determine the content of box 0 at the end, we need to analyze the information provided about the contents of each box:\n",
      "\n",
      "- Box 0 contains the plane.\n",
      "- Box 1 contains the file.\n",
      "- Box 2 contains the key and the knife.\n",
      "- Box 3 contains the computer.\n",
      "- Box 4 contains the fig and the meat.\n",
      "- Box 5 contains the card.\n",
      "- Box 6 contains the ticket.\n",
      "\n",
      "Since there is no indication that the contents of box 0 are changed or that any items are moved between boxes, we can conclude that box 0 still contains the plane.\n",
      "\n",
      "Thus, the content of box 0 at the end remains the same.\n",
      "\n",
      "The answer is:\n",
      "\n",
      "<answer>plane</answer>\n",
      "Correct Natural: 1/1\n",
      "Correct Syntax: 1/1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_nat</td><td>▁</td></tr><tr><td>accuracy_syn</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_nat</td><td>1</td></tr><tr><td>accuracy_syn</td><td>1</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">frosty-bush-8</strong> at: <a href='https://wandb.ai/giospadaccini-eth/codesim/runs/4imax5rn' target=\"_blank\">https://wandb.ai/giospadaccini-eth/codesim/runs/4imax5rn</a><br/> View project at: <a href='https://wandb.ai/giospadaccini-eth/codesim' target=\"_blank\">https://wandb.ai/giospadaccini-eth/codesim</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250115_132922-4imax5rn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "from codesim.experiment import main as start_experiment\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# simulate CLI run\n",
    "sys.argv = [\"codesim/experiment.py\", \n",
    "            \"--dataset_path\", \"data/boxes/batch-1.json\",\n",
    "            \"--model\", \"gpt-4o-mini\",\n",
    "            \"--operation\", \"kim-schuster\",\n",
    "            \"--wandb\"]\n",
    "\n",
    "start_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from codesim.experiment import main as start_experiment\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# simulate CLI run\n",
    "sys.argv = [\"codesim/experiment.py\", \n",
    "            \"--dataset_path\", \"data/StraightLine/n_ops-20_n_vars-3_n_instances-2_batch-1.json\",\n",
    "            \"--model\", \"gpt-4o-mini\",\n",
    "            \"--operation\", \"straight-line\"]\n",
    "\n",
    "start_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from codesim.experiment import main as start_experiment\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# simulate CLI run\n",
    "sys.argv = [\"codesim/experiment.py\", \n",
    "            \"--dataset_path\", \"data/StraightLine/n_ops-20_n_vars-3_n_instances-2_batch-1.json\",\n",
    "            \"--model\", \"gpt-4o-mini\",\n",
    "            \"--operation\", \"sorting\"]\n",
    "\n",
    "start_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
