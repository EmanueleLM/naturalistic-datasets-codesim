{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Straight Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prompts\n",
    "import json \n",
    "import random\n",
    "from codesim.prompt import StraightLine as SL\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/StraightLine/n_ops-20_n_vars-3_n_instances-2_batch-1.json\"))\n",
    "p_syn, p_nat, lab_syn, lab_nat = data[0].values()\n",
    "\n",
    "# Syn\n",
    "var_name = random.choice(list(lab_syn.keys()))\n",
    "gt = lab_syn[var_name]\n",
    "question = SL.questions_syn[0].format(varname=var_name)\n",
    "prompt_syn = SL.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                problem=p_syn, \n",
    "                                question=question)\n",
    "print(prompt_syn)\n",
    "\n",
    "print(\"=\"*30)\n",
    "# Nat\n",
    "agent_name = random.choice(list(lab_nat.keys()))\n",
    "object_name = random.choice(list(lab_nat[agent_name].keys()))\n",
    "gt = lab_nat[agent_name][object_name]\n",
    "question = SL.questions_nat[0].format(varname=object_name, agentname=agent_name)\n",
    "prompt_nat = SL.user_cot.format(prefix=\"\",\n",
    "                                problem=p_nat,\n",
    "                                question=question)\n",
    "print(prompt_nat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critical Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prompts\n",
    "import json \n",
    "import random\n",
    "from codesim.prompt import CriticalPath as CP\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/CriticalPath/n_ops-20_n_vars-4_len_critical_path-10_batch-1.json\"))\n",
    "p_syn, p_nat, lab_syn, lab_nat = data[0].values()\n",
    "\n",
    "# Syn\n",
    "var_name = random.choice(list(lab_syn.keys()))\n",
    "gt = lab_syn[var_name]\n",
    "question = CP.questions_syn[0].format(varname=var_name)\n",
    "prompt_syn = CP.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                problem=p_syn, \n",
    "                                question=question)\n",
    "print(prompt_syn)\n",
    "\n",
    "print(\"=\"*30)\n",
    "# Nat\n",
    "agent_name = random.choice(list(lab_nat.keys()))  # can sample here\n",
    "gt = lab_nat[agent_name]\n",
    "question = CP.questions_nat[0].format(agentname=agent_name)\n",
    "prompt_nat = CP.user_cot.format(prefix=\"\",\n",
    "                                problem=p_nat,\n",
    "                                question=question)\n",
    "print(prompt_nat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prompts\n",
    "import json \n",
    "from codesim.prompt import ParallelPaths as PP\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/ParallelPaths/n_ops-20_n_vars-3_n_instances-2_batch-1.json\"))\n",
    "p_syn, p_nat, lab_syn, lab_nat = data[0].values()\n",
    "\n",
    "# Syn\n",
    "var_names = list(lab_syn.keys())\n",
    "gt = list(lab_syn.values())\n",
    "question = PP.questions_syn[0].format(varnames=\", \".join(var_names))\n",
    "prompt_syn = PP.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                problem=p_syn, \n",
    "                                question=question)\n",
    "print(prompt_syn)\n",
    "\n",
    "print(\"=\"*30)\n",
    "# Nat\n",
    "agent_names = list(lab_nat.keys())\n",
    "object_names = list(lab_nat[agent_names[0]].keys())\n",
    "gt = list(lab_syn.values())\n",
    "question = PP.questions_nat[0].format(varnames=object_names,\n",
    "                                      agentnames=agent_names)\n",
    "prompt_nat = PP.user_cot.format(prefix=\"\",\n",
    "                                problem=p_nat,\n",
    "                                question=question)\n",
    "print(prompt_nat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prompts\n",
    "import json \n",
    "from codesim.prompt import Sort\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/Sort/n_vars-10_ascending-True_batch-1.json\"))\n",
    "p_syn, p_nat, lab_syn, lab_nat = data[0].values()\n",
    "\n",
    "# Syn\n",
    "position = lab_syn[\"position\"]\n",
    "ascending = lab_syn[\"ascending\"]\n",
    "question = Sort.questions_syn[0].format(k=position, heavy = \"heavy\" if ascending else \"light\")\n",
    "prompt_syn = Sort.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                problem=p_syn, \n",
    "                                question=question)\n",
    "print(prompt_syn)\n",
    "# Nat\n",
    "# object_name = list(lab_nat[agent_name].keys())  # same...\n",
    "# gt = lab_nat[agent_name][object_name]\n",
    "question = Sort.questions_nat[0].format(k=position, biggest_smallest= \"biggest\" if ascending else \"smallest\")\n",
    "prompt_nat = Sort.user_cot.format(prefix=\"\",\n",
    "                                problem=p_nat,\n",
    "                                question=question)\n",
    "print(prompt_nat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prompts\n",
    "import json \n",
    "from codesim.prompt import Loops\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/Loops/n_loops-5_n_noisy_loops-2_min_loop_length-3_max_loop-5_batch-1.json\"))\n",
    "p_syn, p_nat, lab_syn, lab_nat = data[0].values()\n",
    "\n",
    "# Syn\n",
    "first_key = list(lab_syn.keys())[0]\n",
    "question = Loops.questions_syn[0].format(varname=first_key)\n",
    "prompt_syn = Loops.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                problem=p_syn, \n",
    "                                question=question)\n",
    "print(prompt_syn)\n",
    "# Nat\n",
    "key_val = list(lab_nat.keys())[0]\n",
    "content, box = key_val.split(\" in \")\n",
    "# object_name = list(lab_nat[agent_name].keys())  # same...\n",
    "# gt = lab_nat[agent_name][object_name]\n",
    "question = Loops.questions_nat[0].format(varname=content, varname_origin=box)\n",
    "prompt_nat = Loops.user_cot.format(prefix=\"\",\n",
    "                                problem=p_nat,\n",
    "                                question=question)\n",
    "print(prompt_nat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prompts\n",
    "import json \n",
    "from codesim.prompt import Boxes\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/boxes/batch-1.json\"))\n",
    "p_syn, p_nat, lab_syn, lab_nat = data[0].values()\n",
    "\n",
    "# Syn\n",
    "first_key = list(lab_syn.keys())[0]\n",
    "question = Boxes.questions_syn[0].format(varname=f\"x{first_key}\")\n",
    "prompt_syn = Boxes.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                problem=p_syn, \n",
    "                                question=question)\n",
    "print(prompt_syn)\n",
    "\n",
    "# Nat\n",
    "first_key = list(lab_nat.keys())[0]\n",
    "# object_name = list(lab_nat[agent_name].keys())  # same...\n",
    "# gt = lab_nat[agent_name][object_name]\n",
    "question = Boxes.questions_nat[0].format(varname=f\"box {first_key}\")\n",
    "prompt_nat = Boxes.user_cot.format(prefix=\"\",\n",
    "                                problem=p_nat,\n",
    "                                question=question)\n",
    "print(prompt_nat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Test exec-time SambaNova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from codesim.prompt import StraightLine as SL\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=\"380072e2-1a5e-4d75-b7a7-d657a457c416\",\n",
    "    base_url=\"https://api.sambanova.ai/v1\",\n",
    ")\n",
    "\n",
    "def call(x:str) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model='Meta-Llama-3.1-405B-Instruct',\n",
    "        messages=[{\"role\":\"system\",\"content\":\"You are a helpful assistant\"},{\"role\":\"user\",\"content\":x}],\n",
    "        temperature =  0.1,\n",
    "        top_p = 0.1\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Get the data\n",
    "data = json.load(open(\"./data/StraightLine/n_ops-20_n_vars-3_n_instances-2_batch-1.json\"))\n",
    "\n",
    "for idx, d in tqdm(enumerate(data)):\n",
    "    p_syn, p_nat, lab_syn, lab_nat = d.values()\n",
    "    var_name = list(lab_syn.keys())[0]  # can sample here\n",
    "    gt = lab_syn[var_name]\n",
    "    question = SL.questions_syn[0].format(varname=var_name)\n",
    "    prompt_syn = SL.user_cot.format(prefix=\"Here's some code:\", \n",
    "                                    problem=p_syn, \n",
    "                                    question=question)\n",
    "    responses = {}\n",
    "    try:\n",
    "        responses[idx] = { \"prompt\": prompt_syn,\n",
    "                           \"response\": call(prompt_syn),\n",
    "                           \"gt\": gt\n",
    "                        }\n",
    "    except:\n",
    "        sleep(5)\n",
    "        \n",
    "json.dump(responses, open(\"responses.json\", \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Retrieve and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesim.problem import StraightLine \n",
    "\n",
    "n_vars = 3; n_instances = 2\n",
    "for n_ops in [10, 20, 30, 40, 50]:\n",
    "    gen = StraightLine(n_ops=n_ops, \n",
    "                    n_vars=n_vars,\n",
    "                    n_instances=n_instances)\n",
    "\n",
    "    # Generate and save 3 batches of 30 problems each\n",
    "    for i in range(3):\n",
    "        gen.generate_data(n_programs=30)\n",
    "        gen.to_file(suffix=\"batch-\" + str(i+1))\n",
    "        gen.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesim.problem import CriticalPath \n",
    "\n",
    "n_vars = 6; len_critical_path = 10\n",
    "for n_ops in [10, 20, 30, 40, 50]:\n",
    "    gen = CriticalPath(n_ops=n_ops, \n",
    "                       n_vars=n_vars,\n",
    "                       len_critical_path=10)\n",
    "\n",
    "    # Generate and save 3 batches of 30 problems each\n",
    "    for i in range(3):\n",
    "        gen.generate_data(n_programs=30)\n",
    "        gen.to_file(suffix=\"batch-\" + str(i+1))\n",
    "        gen.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesim.problem import ParallelPaths \n",
    "\n",
    "n_vars = 3; n_instances = 2\n",
    "for n_ops in [10, 20, 30, 40, 50]:\n",
    "    gen = ParallelPaths(n_ops=n_ops, \n",
    "                        n_vars=n_vars,\n",
    "                        n_instances=n_instances)\n",
    "\n",
    "    # Generate and save 3 batches of 30 problems each\n",
    "    for i in range(3):\n",
    "        gen.generate_data(n_programs=30)\n",
    "        gen.to_file(suffix=\"batch-\" + str(i+1))\n",
    "        gen.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesim.problem import Loops \n",
    "\n",
    "n_loops = [n for n in range(3, 11)]\n",
    "n_noisy_loops = [int(n/2) for n in n_loops]\n",
    "for n,m in zip(n_loops, n_noisy_loops):\n",
    "    gen = Loops(n_loops=n, \n",
    "                n_noisy_loops=m,\n",
    "                min_loop_length=2,\n",
    "                max_loop_length=10)\n",
    "\n",
    "    # Generate and save 3 batches of 30 problems each\n",
    "    for i in range(3):\n",
    "        gen.generate_data(n_programs=30)\n",
    "        gen.to_file(suffix=\"batch-\" + str(i+1))\n",
    "        gen.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codesim.problem import Sort \n",
    "\n",
    "for n_vars in [5, 10, 15, 20, 25]:\n",
    "    # Ascending\n",
    "    gen = Sort(n_vars=n_vars,\n",
    "            ascending=True)\n",
    "\n",
    "    # Generate and save 3 batches of 30 problems each\n",
    "    for i in range(3):\n",
    "        gen.generate_data(n_programs=30)\n",
    "        gen.to_file(suffix=\"batch-\" + str(i+1))\n",
    "        gen.reset()\n",
    "    \n",
    "    # Descending    \n",
    "    gen = Sort(n_vars=n_vars,\n",
    "            ascending=False)\n",
    "\n",
    "    # Generate and save 3 batches of 30 problems each\n",
    "    for i in range(3):\n",
    "        gen.generate_data(n_programs=30)\n",
    "        gen.to_file(suffix=\"batch-\" + str(i+1))\n",
    "        gen.reset()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(object_vocabulary_file='data/objects_with_bnc_frequency.csv', disjoint_object_vocabulary_file=None, disjoint_object_splits='test', output_dir='data/boxes', seed=2255, num_boxes=7, expected_num_items_per_box=1, max_items_per_box=3, num_samples=30, num_operations=10, disjoint_numops=False, zero_shot=False, include_modifiers='never', omit_modifiers_in_ops='never', alternative_forms='never', rarify=False, all_contents_operation=False)\n",
      "finished sampling 60 sequences of length 10.\n",
      "Saved outputs to data/boxes.\n",
      "Namespace(object_vocabulary_file='data/objects_with_bnc_frequency.csv', disjoint_object_vocabulary_file=None, disjoint_object_splits='test', output_dir='data/boxes', seed=2255, num_boxes=7, expected_num_items_per_box=1, max_items_per_box=4, num_samples=30, num_operations=10, disjoint_numops=False, zero_shot=False, include_modifiers='never', omit_modifiers_in_ops='never', alternative_forms='never', rarify=False, all_contents_operation=False)\n",
      "finished sampling 60 sequences of length 10.\n",
      "Saved outputs to data/boxes.\n",
      "Namespace(object_vocabulary_file='data/objects_with_bnc_frequency.csv', disjoint_object_vocabulary_file=None, disjoint_object_splits='test', output_dir='data/boxes', seed=2255, num_boxes=7, expected_num_items_per_box=1, max_items_per_box=5, num_samples=30, num_operations=10, disjoint_numops=False, zero_shot=False, include_modifiers='never', omit_modifiers_in_ops='never', alternative_forms='never', rarify=False, all_contents_operation=False)\n",
      "finished sampling 60 sequences of length 10.\n",
      "Saved outputs to data/boxes.\n",
      "Namespace(object_vocabulary_file='data/objects_with_bnc_frequency.csv', disjoint_object_vocabulary_file=None, disjoint_object_splits='test', output_dir='data/boxes', seed=2255, num_boxes=7, expected_num_items_per_box=1, max_items_per_box=6, num_samples=30, num_operations=10, disjoint_numops=False, zero_shot=False, include_modifiers='never', omit_modifiers_in_ops='never', alternative_forms='never', rarify=False, all_contents_operation=False)\n",
      "finished sampling 60 sequences of length 10.\n",
      "Saved outputs to data/boxes.\n",
      "Namespace(object_vocabulary_file='data/objects_with_bnc_frequency.csv', disjoint_object_vocabulary_file=None, disjoint_object_splits='test', output_dir='data/boxes', seed=2255, num_boxes=7, expected_num_items_per_box=1, max_items_per_box=7, num_samples=30, num_operations=10, disjoint_numops=False, zero_shot=False, include_modifiers='never', omit_modifiers_in_ops='never', alternative_forms='never', rarify=False, all_contents_operation=False)\n",
      "finished sampling 60 sequences of length 10.\n",
      "Saved outputs to data/boxes.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from codesim.kim_schuster import real_main\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "for n_items in [3, 4, 5, 6, 7]:\n",
    "    # simulate CLI run\n",
    "    sys.argv = [\"codesim/kim_schuster.py\", \n",
    "                \"--max_items_per_box\", f\"{n_items}\",\n",
    "                \"--num_samples\", \"30\"]\n",
    "\n",
    "    real_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Straight Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting the Tests for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from codesim.experiment import main as start_experiment\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# simulate CLI run\n",
    "sys.argv = [\"codesim/experiment.py\", \n",
    "            \"--dataset_path\", \"data/boxes/batch-1.json\",\n",
    "            \"--model\", \"gpt-4o-mini\",\n",
    "            \"--operation\", \"kim-schuster\"]\n",
    "\n",
    "start_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from codesim.experiment import main as start_experiment\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# simulate CLI run\n",
    "sys.argv = [\"codesim/experiment.py\", \n",
    "            \"--dataset_path\", \"data/StraightLine/n_ops-20_n_vars-3_n_instances-2_batch-1.json\",\n",
    "            \"--model\", \"gpt-4o-mini\",\n",
    "            \"--operation\", \"straight-line\"]\n",
    "\n",
    "start_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from codesim.experiment import main as start_experiment\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# simulate CLI run\n",
    "sys.argv = [\"codesim/experiment.py\", \n",
    "            \"--dataset_path\", \"data/StraightLine/n_ops-20_n_vars-3_n_instances-2_batch-1.json\",\n",
    "            \"--model\", \"gpt-4o-mini\",\n",
    "            \"--operation\", \"sorting\"]\n",
    "\n",
    "start_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
